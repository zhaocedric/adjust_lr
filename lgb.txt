train_data = './data.csv'   # 在当前路径下将data.csv换成要进行训练的xxx.csv
model_file='./model.txt'   #(默认)
test_data = './data2.csv'  # 如果有测试数据
test_data = train_data     # 如果没测试数据
num_boost_round = 100      # 进行训练的迭代总数，建议 100 - 500之间，如果时间足够可以加大,不宜超过1000防止过拟合

##### 需要进行安装的包 ######
import pandas as pd
import lightgbm as lgb 
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split

params = {
    'task': 'train',  #### 构建lightgbm训练模型
    'boosting_type': 'gbdt',  # GBDT算法为基础，也可以选用随机森林‘rf’
    'objective': 'poisson',  # 回归类型，如果是二分类这里是‘binary’
    'metric': 'rmse',  # 平方根损失，作为评价标准。 因为是回归问题，以预测结果与真实值之间的差值平方根作为评判标准,
    'max_bin': 255,  # 大会有更准的效果,更慢的速度
    'learning_rate': 0.1,  # 学习率一般设置在 0.1左右，可微调
    'num_leaves': 64,  # 大会更准,但可能会有过拟合，数据量较小时建议调小
    'max_depth': -1,  # 小数据集下限制最大深度可防止过拟合,小于0表示无限制
    'feature_fraction': 0.8,  # 防止过拟合，默认
    'bagging_freq': 5,  # 防止过拟合，默认
    'bagging_fraction': 0.8,  # 防止过拟合，默认值
    'min_data_in_leaf': 21,  # 防止过拟合
    'min_sum_hessian_in_leaf': 3.0,  # 防止过拟合，默认
    'header': True  # 数据集是否带表头
}



########### 按照原来的表格格式data.csv保存训练的数据，注意out名字不变，以下内容可保持默认 ##############
dataset = pd.read_csv(train_data)  # 训练集
d_x = dataset.iloc[:, 1:].values
d_y = dataset['out'].values
dataset_future = pd.read_csv(test_data)  # 测试集
d_future_x = dataset_future.iloc[:, 1:].values
train_X, valid_X, train_Y, valid_Y = train_test_split(
    d_x, d_y, test_size=0.2, random_state=2)  # 将训练集分为训练集+验证集
lgb_train = lgb.Dataset(train_X, label=train_Y)
lgb_eval = lgb.Dataset(valid_X, label=valid_Y, reference=lgb_train)
print("Training...")
bst = lgb.train(
    params,
    lgb_train,
    valid_sets=[lgb_eval],
    num_boost_round=num_boost_round,
    early_stopping_rounds=num_boost_round//5)  # 构建lgb训练模型
print("Saving Model...")
bst.save_model(model_file)  # 保存模型
print("Predicting...")
predict_result = bst.predict(d_future_x)  # 预测的结果

list_feature_name = list(dataset.columns[1:])
list_feature_importance = list(bst.feature_importance(
    importance_type='split', iteration=-1))
dataframe_feature_importance = pd.DataFrame(
    {'feature_name': list_feature_name, 'importance': list_feature_importance})
print(dataframe_feature_importance)
x = range(len(list_feature_name))
# plt.xticks(x, list_feature_name, rotation=90, fontsize=14)
# plt.plot(x, list_feature_importance)


############ 将结果构建成字典形式 ##############
dic = {}
for i in range(len(list_feature_name)):
    dic[list_feature_name[i]] = list_feature_importance[i]

########## 优化作图，默认不用修改 ##############
s = sorted(dic.items(), key=lambda x: x[1], reverse=False)  # 对dict 按照value排序 True表示翻转 ,转为了列表形式
print(s)
x_x = []
y_y = []
for i in s:
    x_x.append(i[0])
    y_y.append(i[1])

x = x_x
y = y_y

fig, ax = plt.subplots()
ax.barh(x, y, color="deepskyblue")
labels = ax.get_xticklabels()
plt.setp(labels, rotation=0, horizontalalignment='right')

for a, b in zip(x, y):
    plt.text(b+1, a, b, ha='center', va='center')
ax.legend(["importance"],loc="lower right")

plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
plt.ylabel('input_name')
plt.xlabel('importance_value')
plt.rcParams['savefig.dpi'] = 300  # 图片像素
plt.rcParams['figure.dpi'] = 300  # 分辨率
plt.rcParams['figure.figsize'] = (15.0, 8.0)  # 尺寸
plt.title("feture_analysis")
plt.savefig('result.png')
plt.show()

########## 优化作图-极坐标图，默认不用修改 ##############


list_feature_name = list_feature_name
list_feature_importance = list_feature_importance 
#list_feature_importance = [211,304,11,322,161,133,93,871,1249,117,78,63,288,2399]

dataLength = len(list_feature_importance)

# 把园等分为dataLength份
angles = np.linspace(0,2*np.pi,dataLength,endpoint=False)
list_feature_importance.append(list_feature_importance[0])
angles = np.append(angles,angles[0])
plt.polar(angles,list_feature_importance,'rv--',lw=2)
plt.thetagrids(angles*180/np.pi,list_feature_name,fontproperties = 'importance')
plt.fill(angles,list_feature_importance,facecolor='r',alpha = 0.4)
plt.show()



################## 饼图 ########### 默认
plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签
labels = list_feature_name
sizes = list_feature_importance[:len(labels)]
explode = [0] * len(sizes)
plt.pie(sizes,explode=explode,labels=labels,autopct='%1.1f%%',shadow=False,startangle=150)
plt.title("importance")
plt.show()  




